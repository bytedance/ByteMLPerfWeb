# 接入 Micro Perf

## 创建 Backend

参考已有的 GPU 实现，在`ByteMLPerf/byte_micro_perf/backends/`路径下，创建对应硬件的文件夹，新硬件接口`backend_xpu.py`和所需运行环境的`requirements.txt`。
需要注意的是在继承 build_tensor, \_run_operation, initialize_ccl 等函数时时，注意修改为对应硬件的函数(如 torch.cuda.synchronize())。

```python title=backend_gpu.py
class BackendGPU(Backend):

    # 获取硬件名字
    def get_device_name(self):
        return torch.cuda.get_device_name(0)

    # 若提供了硬件属性文件，则读取文件获取内存信息
    def get_backend_properties(self):
        self.memory_limit = int(
            torch.cuda.get_device_properties(0).total_memory / (1024**3)
        )

        if self.vendor_path is not None and os.path.exists(self.vendor_path) and (self.vendor_path).endswith(".json"):
            with open(self.vendor_path, "r") as f:
                self.hw_info_dict = json.load(f)
                # if the vendor path does not exist, please set this param manaually
                self.bandwidth_limit = self.hw_info_dict["内存参数"]["内存"]["内存带宽(GB/s)"]
        else:
            log.warning(
                "Vendor_path: [ {} ] was not found or not a full path points to json, please check your path!!! Otherwise, please set the hardware info manaually.".format(
                    self.vendor_path
                )
            )

    # 根据硬件的内存容量，提前创建多个输入张量，并随机选择某一个作为输入，避免L2 cache
    # 若算子需要额外处理输入张量，则可以在process_inputs函数内进一步处理。返回合适的输入
    def build_tensor(self, input_shapes, dtype):
        torch.cuda.empty_cache()
        torch_dtype = getattr(torch, dtype)

        # compute size of input and output tensors
        if hasattr(self.op, "compute_size"):
            bytes_per_cnt = self.op.compute_size(input_shapes, dtype)
        # default: input_tensors_size == output_tensor_size, all tensors have same dtype
        else:
            dtype_size = get_dtype_bytes(dtype)
            element_num = 2 * sum([math.prod(shape) for shape in input_shapes])
            bytes_per_cnt = dtype_size * element_num

        # compute max avail tensors for compute
        avail_bytes = (self.memory_limit - 4) * 1024**3
        avail_cnts = avail_bytes // bytes_per_cnt
        max_data_cnt = min(self.iterations, avail_cnts)

        # create input tensors for each op
        input_tensors_list = []
        for _ in range(max_data_cnt):
            # create input tensors
            if hasattr(self.op, "custom_create_tensors"):
                input_tensors = self.op.custom_create_tensors(input_shapes, torch_dtype, "cuda")
                input_tensors_list.append(input_tensors)
            # default: all input tensors have same dtype
            else:
                if torch_dtype in [torch.int8, torch.int32]:
                    input_tensors = [
                        torch.randint(-3, 3, size=shape, dtype=torch_dtype, device="cuda")
                        for shape in input_shapes
                    ]
                else:
                    input_tensors = [
                        torch.randn(shape, dtype=torch_dtype, device="cuda")
                        for shape in input_shapes
                    ]
                input_tensors_list.append(input_tensors)
        if hasattr(self.op, "process_inputs"):
            input_tensors_list = [
                self.op.process_inputs(*(input_tensor))
                for input_tensor in input_tensors_list
            ]
        return input_tensors_list, max_data_cnt, bytes_per_cnt

    # 运行相应的算子操作
    def _run_operation(self, operation, inputs):
        result = operation(*inputs)
        return result

    # 重载正确的同步函数
    def device_synchronize(self):
        torch.cuda.synchronize()
        return True

    # 配置分布式相关的参数，如master_addr，master_port等
    # 设置对应的backend
    def initialize_ccl(self, rank, world_size):
        """
        initialize distributed process groups and relevant ENVs
        """

        # set cuda device
        torch.cuda.set_device(rank)

        # set envs
        os.environ["MASTER_ADDR"] = "127.0.0.1"
        os.environ["MASTER_PORT"] = "49373"
        os.environ["LOCAL_RANK"] = str(rank)
        os.environ["RANK"] = str(rank)
        os.environ["WORLD_SIZE"] = str(world_size)

        # Call the init process
        torch.distributed.init_process_group(
            backend="nccl",
            world_size=world_size,
            rank=rank
        )

        # create group
        self.setup_2d_group()

        log.info(f"DIST: rank {rank}, world_size {world_size}")
        return True

    # 创建2D group
    def setup_2d_group(self):
        # get rank and set device
        self.rank = dist.get_rank()
        torch.cuda.set_device(self.rank)

        origin_store_based_barrier = dist_c10d._store_based_barrier
        dist_c10d._store_based_barrier = lambda *a, **kw: None

        self.world_size = dist.get_world_size()
        self.ranks = range(0, self.world_size)
        group = dist.new_group(self.ranks)
        if self.rank in self.ranks:
            self.group = group

        dist_c10d._store_based_barrier = origin_store_based_barrier

        # wait for all ranks finish group initializing
        torch.distributed.barrier()

    # 摧毁所有的进程group
    def destroy_process_group(self):
        dist.destroy_process_group()
```

## Workload 说明

```json title=softmax.json
{
    "operator": "softmax", #算子名
    "iterations": 100, #迭代次数
    "input_shape_list": [
        [
            131072,
            64
        ],
        [
            131072,
            1024
        ]
    ], #算子输入形状，可同时评测多个不同的形状，注意不要超过内存容量进而OOM
    "dtype": [
        "float32",
        "bfloat16",
        "half"
    ] #数据类型，可填写硬件支持的数据类型
}
```

## 评估指标说明

- Memory Size(MB): 算子输入的访存量
- Group: 通信算子的切分 group 数量
- Bus bandwidth(GB/s): 通信算子的通信带宽，计算算子为 None
- Algo bandwidth(GB/s): 算子的 IO 带宽
- Bandwidth Utilization(%): 算子的内存带宽利用率
- Avg latency(us): N 次循环的平均延迟时间
